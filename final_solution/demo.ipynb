{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Financial Forecasting - Demo v3.1\n",
    "\n",
    "–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ **FinancialForecaster** –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è **–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π** (returns) –Ω–∞ 1-20 –¥–Ω–µ–π –≤–ø–µ—Ä–µ–¥.\n",
    "\n",
    "## ‚ö†Ô∏è –í–ê–ñ–ù–û: –§–æ—Ä–º–∞—Ç p1-p20\n",
    "\n",
    "**p1-p20 = –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –î–û–•–û–î–ù–û–°–¢–ò (returns), –ù–ï –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏!**\n",
    "\n",
    "## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è:\n",
    "- `solution.py` - –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å FinancialForecaster (160 –º–æ–¥–µ–ª–µ–π)\n",
    "- `demo.ipynb` - —ç—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫\n",
    "- `FORMAT_FIX_CRITICAL.md` - –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–æ—Ä–º–∞—Ç–µ\n",
    "\n",
    "## –§–æ—Ä–º–∞—Ç submission:\n",
    "\n",
    "```csv\n",
    "ticker,p1,p2,p3,p4,p5,...,p20\n",
    "AFLT,0.0123,-0.0089,0.0234,0.0012,-0.0156,...,-0.0112\n",
    "SBER,-0.0067,0.0234,0.0089,0.0012,-0.0145,...,0.0045\n",
    "```\n",
    "\n",
    "**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**:\n",
    "- `p1 = 0.0123` ‚Üí –æ–∂–∏–¥–∞–µ—Ç—Å—è +1.23% —á–µ—Ä–µ–∑ 1 –¥–µ–Ω—å\n",
    "- `p5 = -0.0156` ‚Üí –æ–∂–∏–¥–∞–µ—Ç—Å—è -1.56% —á–µ—Ä–µ–∑ 5 –¥–Ω–µ–π\n",
    "- `p20 = 0.0198` ‚Üí –æ–∂–∏–¥–∞–µ—Ç—Å—è +1.98% —á–µ—Ä–µ–∑ 20 –¥–Ω–µ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## 0. –ò–º–ø–æ—Ä—Ç—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì –ò–º–ø–æ—Ä—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã\n",
      "‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è solution.py (returns, –Ω–µ probabilities)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥—É–ª—è –µ—Å–ª–∏ —É–∂–µ –±—ã–ª –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω\n",
    "if 'solution' in sys.modules:\n",
    "    del sys.modules['solution']\n",
    "\n",
    "from solution import FinancialForecaster\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì –ò–º–ø–æ—Ä—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã\")\n",
    "print(\"‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è solution.py (returns, –Ω–µ probabilities)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init",
   "metadata": {},
   "source": [
    "## 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Å –∞–Ω—Å–∞–º–±–ª–µ–º –∏–∑ 160 –º–æ–¥–µ–ª–µ–π:\n",
    "- 2 LGBM (aggressive + conservative) √ó 2 (regressor + classifier)\n",
    "- 1 CatBoost √ó 2 (regressor + classifier)\n",
    "- 1 Ridge regressor + scaler\n",
    "- –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ 20 –¥–Ω–µ–π = 8 –æ–±—ä–µ–∫—Ç–æ–≤ √ó 20 = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "model_init",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞\n",
      "  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –º–æ–¥–µ–ª–µ–π: 7\n",
      "  –ú–æ–¥–µ–ª–∏: ['lgbm_aggressive', 'lgbm_conservative', 'lgbm_clf_aggressive', 'lgbm_clf_conservative', 'catboost', 'catboost_clf', 'ridge']\n"
     ]
    }
   ],
   "source": [
    "model = FinancialForecaster(random_state=42)\n",
    "\n",
    "print(\"‚úì –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞\")\n",
    "print(f\"  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –º–æ–¥–µ–ª–µ–π: {len(model.model_params)}\")\n",
    "print(f\"  –ú–æ–¥–µ–ª–∏: {list(model.model_params.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_header",
   "metadata": {},
   "source": [
    "## 2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "‚è±Ô∏è **–í—Ä–µ–º—è**: ~15-25 –º–∏–Ω—É—Ç –¥–ª—è –≤—Å–µ—Ö 160 –º–æ–¥–µ–ª–µ–π\n",
    "\n",
    "–ü—Ä–æ—Ü–µ—Å—Å:\n",
    "1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "2. Sentiment analysis (keyword-based)\n",
    "3. Feature engineering (~120 —Ñ–∏—á–µ–π)\n",
    "4. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ç–∏–∫–µ—Ä–æ–≤\n",
    "5. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "6. **–û–±—É—á–µ–Ω–∏–µ 160 –º–æ–¥–µ–ª–µ–π** —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –≤–µ—Å–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò\n",
      "============================================================\n",
      "\n",
      "[1/6] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n",
      "  ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 24197 —Å–≤–µ—á–µ–π –ø–æ 19 —Ç–∏–∫–µ—Ä–∞–º\n",
      "  ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 25425 –Ω–æ–≤–æ—Å—Ç–µ–π\n",
      "\n",
      "[2/6] –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π (sentiment analysis)...\n",
      "  ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π sentiment: 0.289\n",
      "\n",
      "[3/6] Feature engineering...\n",
      "  ‚Ä¢ –°–æ–∑–¥–∞–Ω–æ 113 —Ñ–∏—á\n",
      "\n",
      "[4/6] –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ç–∏–∫–µ—Ä–æ–≤...\n",
      "  ‚Ä¢ –°–æ–∑–¥–∞–Ω–æ 4 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Ç–∏–∫–µ—Ä–æ–≤\n",
      "\n",
      "[5/6] –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...\n",
      "  ‚Ä¢ Tree features: 75\n",
      "  ‚Ä¢ Macro features: 50\n",
      "\n",
      "[6/6] –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π...\n",
      "  ‚Ä¢ –û–±—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è –¥–ª—è p1-p20...\n",
      "    –ú–æ–¥–µ–ª–∏ –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç: 2xLGBM + CatBoost + Ridge = 4 –º–æ–¥–µ–ª–∏\n",
      "    Tree features: 75, Macro features: 50\n"
     ]
    }
   ],
   "source": [
    "train_candles_path = '../forecast_data/candles.csv'\n",
    "train_news_path = '../forecast_data/news.csv'\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ (–¥–æ–ª–≥–æ!)\n",
    "model.fit(\n",
    "    candles_path=train_candles_path,\n",
    "    news_path=train_news_path\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_header",
   "metadata": {},
   "source": [
    "## 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ 160 –º–æ–¥–µ–ª–µ–π + –≤–µ—Å–∞ –∞–Ω—Å–∞–º–±–ª–µ–π + scalers –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª.\n",
    "\n",
    "üíæ –†–∞–∑–º–µ—Ä: ~50-100 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_model_v3.pkl')\n",
    "\n",
    "print(\"‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: trained_model_v3.pkl\")\n",
    "print(f\"  –ú–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(model.models)}\")\n",
    "print(f\"  Scalers: {len(model.scalers)}\")\n",
    "print(f\"  Ensemble weights: {len(model.ensemble_weights)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "predict_header",
   "metadata": {},
   "source": [
    "## 4. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "‚è±Ô∏è **–í—Ä–µ–º—è**: ~30 —Å–µ–∫—É–Ω–¥\n",
    "\n",
    "–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è **–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π** (returns) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ –Ω–∞ 20 –¥–Ω–µ–π –≤–ø–µ—Ä–µ–¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candles_path = '../forecast_data/candles_2.csv'\n",
    "test_news_path = '../forecast_data/news_2.csv'\n",
    "\n",
    "submission = model.predict(\n",
    "    candles_path=test_candles_path,\n",
    "    news_path=test_news_path,\n",
    "    output_path='submission_v3.csv'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Submission —Å–æ–∑–¥–∞–Ω: submission_v3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results_header",
   "metadata": {},
   "source": [
    "## 5. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "\n",
    "–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ **–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏**, –∞ –Ω–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"–ê–ù–ê–õ–ò–ó SUBMISSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n–§–æ—Ä–º–∞: {submission.shape}\")\n",
    "print(f\"–¢–∏–∫–µ—Ä–æ–≤: {submission['ticker'].nunique()}\")\n",
    "\n",
    "print(\"\\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
    "print(submission.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –î–û–•–û–î–ù–û–°–¢–Ø–ú\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "returns_cols = [f'p{i}' for i in range(1, 21)]\n",
    "stats = submission[returns_cols].describe()\n",
    "print(stats)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"–ü–†–û–í–ï–†–ö–ê –§–û–†–ú–ê–¢–ê\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ returns, –∞ –Ω–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\n",
    "for col in ['p1', 'p5', 'p10', 'p15', 'p20']:\n",
    "    min_val = submission[col].min()\n",
    "    max_val = submission[col].max()\n",
    "    mean_val = submission[col].mean()\n",
    "    \n",
    "    # Returns –æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–ª–∏ > 1\n",
    "    # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—Å–µ–≥–¥–∞ –≤ [0, 1]\n",
    "    is_return = (min_val < 0) or (max_val > 1)\n",
    "    status = \"‚úÖ RETURN\" if is_return else \"‚ö†Ô∏è  PROB?\"\n",
    "    \n",
    "    print(f\"{col}: [{min_val:7.4f}, {max_val:7.4f}], mean={mean_val:7.4f} ‚Üí {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"–ü–†–ò–ú–ï–†–´ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for ticker in submission['ticker'].head(3):\n",
    "    row = submission[submission['ticker'] == ticker].iloc[0]\n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(f\"  p1  (1 –¥–µ–Ω—å):  {row['p1']:+.4f} ({row['p1']*100:+.2f}%)\")\n",
    "    print(f\"  p5  (5 –¥–Ω–µ–π):  {row['p5']:+.4f} ({row['p5']*100:+.2f}%)\")\n",
    "    print(f\"  p10 (10 –¥–Ω–µ–π): {row['p10']:+.4f} ({row['p10']*100:+.2f}%)\")\n",
    "    print(f\"  p20 (20 –¥–Ω–µ–π): {row['p20']:+.4f} ({row['p20']*100:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_header",
   "metadata": {},
   "source": [
    "## 6. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –ó–∞–≥—Ä—É–∑–∫–∞ –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–ï—Å–ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞, –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏ –¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä\n",
    "loaded_model = FinancialForecaster()\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å\n",
    "loaded_model.load('trained_model_v3.pkl')\n",
    "\n",
    "# –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "submission2 = loaded_model.predict(\n",
    "    candles_path=test_candles_path,\n",
    "    news_path=test_news_path,\n",
    "    output_path='submission_from_loaded.csv'\n",
    ")\n",
    "\n",
    "print(\"‚úì –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–¥–µ–ª–∞–Ω—ã —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é\")\n",
    "print(f\"  –¢–∏–∫–µ—Ä–æ–≤: {len(submission2)}\")\n",
    "print(f\"  –ö–æ–ª–æ–Ω–æ–∫: {len(submission2.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation",
   "metadata": {},
   "source": [
    "## 7. –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞\n",
    "\n",
    "–£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ submission –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_submission(df, name=\"submission\"):\n",
    "    \"\"\"–í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ submission\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"–í–ê–õ–ò–î–ê–¶–ò–Ø: {name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫\n",
    "    required_cols = ['ticker'] + [f'p{i}' for i in range(1, 21)]\n",
    "    if list(df.columns) == required_cols:\n",
    "        print(\"‚úÖ –ö–æ–ª–æ–Ω–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ: ticker,p1,p2,...,p20\")\n",
    "    else:\n",
    "        print(\"‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–´–ï –ö–û–õ–û–ù–ö–ò!\")\n",
    "        return False\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–∏–∫–µ—Ä–æ–≤\n",
    "    if not df['ticker'].duplicated().any():\n",
    "        print(f\"‚úÖ –í—Å–µ —Ç–∏–∫–µ—Ä—ã —É–Ω–∏–∫–∞–ª—å–Ω—ã ({len(df)} —Å—Ç—Ä–æ–∫)\")\n",
    "    else:\n",
    "        print(\"‚ùå –ï–°–¢–¨ –î–£–ë–õ–ò–ö–ê–¢–´ –¢–ò–ö–ï–†–û–í!\")\n",
    "        return False\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —ç—Ç–æ returns (–Ω–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)\n",
    "    has_negatives = any(df[f'p{i}'].min() < 0 for i in range(1, 21))\n",
    "    has_outliers = any(df[f'p{i}'].max() > 1 for i in range(1, 21))\n",
    "    \n",
    "    if has_negatives or has_outliers:\n",
    "        print(\"‚úÖ –°–æ–¥–µ—Ä–∂–∏—Ç RETURNS (–µ—Å—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∏–ª–∏ >1)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  –í–°–ï –ó–ù–ê–ß–ï–ù–ò–Ø –í [0,1] - –í–û–ó–ú–û–ñ–ù–û –í–ï–†–û–Ø–¢–ù–û–°–¢–ò!\")\n",
    "    \n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    all_returns = df[[f'p{i}' for i in range(1, 21)]].values.flatten()\n",
    "    print(f\"\\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:\")\n",
    "    print(f\"  Min: {all_returns.min():.4f}\")\n",
    "    print(f\"  Max: {all_returns.max():.4f}\")\n",
    "    print(f\"  Mean: {all_returns.mean():.4f}\")\n",
    "    print(f\"  Std: {all_returns.std():.4f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ –í–ê–õ–ò–î–ê–¶–ò–Ø –ü–†–û–ô–î–ï–ù–ê!\")\n",
    "    return True\n",
    "\n",
    "# –í–∞–ª–∏–¥–∏—Ä—É–µ–º\n",
    "validate_submission(submission, \"submission_v3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## üìã –†–µ–∑—é–º–µ\n",
    "\n",
    "### –ß—Ç–æ –º—ã —Å–¥–µ–ª–∞–ª–∏:\n",
    "1. ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ –º–æ–¥–µ–ª—å (160 –º–æ–¥–µ–ª–µ–π)\n",
    "2. ‚úÖ –û–±—É—á–∏–ª–∏ –Ω–∞ candles.csv + news.csv (~15-25 –º–∏–Ω)\n",
    "3. ‚úÖ –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ –º–æ–¥–µ–ª—å (~50-100 MB)\n",
    "4. ‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∏ submission —Å **–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏** (–Ω–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏!)\n",
    "5. ‚úÖ –ü—Ä–æ–≤–µ—Ä–∏–ª–∏ —Ñ–æ—Ä–º–∞—Ç\n",
    "\n",
    "### –§–æ—Ä–º–∞—Ç submission:\n",
    "```\n",
    "ticker,p1,p2,p3,...,p20\n",
    "AFLT,0.0123,-0.0089,0.0234,...,-0.0112\n",
    "```\n",
    "\n",
    "### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:\n",
    "- **LGBM Aggressive** (reg + clf) √ó 20 –¥–Ω–µ–π\n",
    "- **LGBM Conservative** (reg + clf) √ó 20 –¥–Ω–µ–π\n",
    "- **CatBoost** (reg + clf) √ó 20 –¥–Ω–µ–π\n",
    "- **Ridge** (reg + scaler) √ó 20 –¥–Ω–µ–π\n",
    "- **–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞** —á–µ—Ä–µ–∑ scipy.optimize\n",
    "\n",
    "### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\n",
    "1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ `test_returns_format.py` –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "2. Submit —Ñ–∞–π–ª `submission_v3.csv`\n",
    "3. –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã —á–µ—Ä–µ–∑ `optimize_hyperparams.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
